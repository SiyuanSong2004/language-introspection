{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparedata\n",
    "process and merge model outputs in [`model_output`](model_output) and save complete daqta to [`alldata`](alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "import re\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "MODELS_INSTRUCT = ['llama-3.1-8b-instruct','llama-3.1-70b-instruct','llama-3.3-70b-instruct','qwen2.5-1.5b-instruct','qwen2.5-7b-instruct','qwen2.5-72b-instruct','mistral-large-instruct-2411']\n",
    "MODELS_BASE = ['llama-3.1-8b','llama-3.1-70b','qwen2.5-1.5b','qwen2.5-7b','qwen2.5-72b', 'llama-3.1-405b','olmo-2-1124-7b','olmo-2-1124-7b-stage2-ingredient1-step11931-tokens50B','olmo-2-1124-7b-stage2-ingredient2-step11931-tokens50B','olmo-2-1124-7b-stage2-ingredient3-step11931-tokens50B', 'olmo-2-1124-13b', 'olmo-2-1124-13b-stage2-ingredient1-step11931-tokens100B','olmo-2-1124-13b-stage2-ingredient2-step11931-tokens100B','olmo-2-1124-13b-stage2-ingredient3-step11931-tokens100B']\n",
    "\n",
    "MODELS = MODELS_INSTRUCT + MODELS_BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions, referred to https://github.com/jennhu/response-to-DGL/blob/87228acbc3f65b169f0ec3cdebef9eb7c1043398/notebooks/main.ipynb\n",
    "def read_model_csvs(folder, model_substr=None):\n",
    "    \"\"\"Helper function for reading CSV files from a folder.\n",
    "    Expects files to be named by model.\"\"\"\n",
    "    # get all files, and sort them\n",
    "    files = sorted(listdir(folder))\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        # Only read files containing the specified substring.\n",
    "        if model_substr is not None and model_substr not in f:\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.read_csv(f\"{folder}/{f}\", )\n",
    "            #extract model name and data name and load to df\n",
    "            model, dataset = f.split('_', 1)\n",
    "            dataset = dataset.replace('.csv', '')\n",
    "            #print(f'READING DATA: {model} on {dataset}')\n",
    "            df[\"model\"] = model\n",
    "            df[\"dataset\"] = dataset\n",
    "            df['model_family'] = 'qwen' if 'qwen'in model else model.split('-')[0]\n",
    "            df['model_gen'] = '2.5' if 'qwen'in model else model.split('-')[1]\n",
    "            df['model_size'] = float(re.search(r'(\\d+(\\.\\d*)?)b', model).group(1)) if 'b' in model else 123\n",
    "            df['model_type'] = 'instruct' if 'instruct' in model else 'base'\n",
    "            dfs.append(df)\n",
    "        except pd.errors.ParserError:\n",
    "            print(f\"Skipping file due to parsing error: {f}\")\n",
    "            continue\n",
    "    \n",
    "    data = pd.concat(dfs)\n",
    "    return data\n",
    "\n",
    "def try_index(df, index):\n",
    "    \"\"\"Helper function for trying to look up data from a dataframe.\"\"\"\n",
    "    try:\n",
    "        return df.loc[index]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def sort_by_models (df, models):\n",
    "    \"\"\"Helper function for sorting data by models.\"\"\"\n",
    "    df['model'] = pd.Categorical(df['model'], models)\n",
    "    df = df.sort_values('model')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Acceptability Judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_aj_data(folder='acceptability',models=None):\n",
    "    \"\"\"Helper function for reading and processing the acceptability judgment data.\"\"\"\n",
    "    df = read_model_csvs(f'model_output/{folder}')\n",
    "\n",
    "    if models is not None:\n",
    "        # Optionally subset models.\n",
    "        df = df[df.model.isin(models)]\n",
    "    \n",
    "    df['sumLP_diff'] = df['direct_sum_score_gram'] - df['direct_sum_score_ungram']\n",
    "    df['meanLP_diff'] = df['direct_mean_score_gram'] - df['direct_mean_score_ungram']\n",
    "    df['sumLP_ans'] = df['direct_sum_score_correct']\n",
    "    df['meanLP_ans'] = df['direct_mean_score_correct']\n",
    "\n",
    "\n",
    "    # process prompt 1 to 5\n",
    "    for i in range(1,6):\n",
    "        df[f'prompt{i}_diff'] = df[f'prompt{i}_score_gram'] - df[f'prompt{i}_score_ungram']\n",
    "        df[f'prompt{i}_ans'] = df[f'prompt{i}_correct_mean']\n",
    "    \n",
    "    # process prompt 6 8 10\n",
    "    for i in [6,8,10]:\n",
    "       pid=(i-5)//2+6\n",
    "       df[f'prompt{pid}_gram'] = df[f'prompt{i}_score_gram'] - df[f'prompt{i}_score_ungram']\n",
    "       df[f'prompt{pid}_ungram'] = df[f'prompt{i+1}_score_gram'] - df[f'prompt{i+1}_score_ungram']\n",
    "       df[f'prompt{pid}_diff'] = df[f'prompt{pid}_gram'] - df[f'prompt{pid}_ungram']\n",
    "       df[f'prompt{pid}_ans'] = df[f'prompt{pid}_gram'] > df[f'prompt{pid}_ungram']\n",
    "    \n",
    "    # rename models\n",
    "    #df = model_rename(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_grammatical</th>\n",
       "      <th>sentence_ungrammatical</th>\n",
       "      <th>source</th>\n",
       "      <th>paradigm</th>\n",
       "      <th>phenomenon</th>\n",
       "      <th>LS_grammatical</th>\n",
       "      <th>LS_ungrammatical</th>\n",
       "      <th>LS_diff</th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>direct_sum_score_gram</th>\n",
       "      <th>...</th>\n",
       "      <th>prompt6_diff</th>\n",
       "      <th>prompt6_ans</th>\n",
       "      <th>prompt7_gram</th>\n",
       "      <th>prompt7_ungram</th>\n",
       "      <th>prompt7_diff</th>\n",
       "      <th>prompt7_ans</th>\n",
       "      <th>prompt8_gram</th>\n",
       "      <th>prompt8_ungram</th>\n",
       "      <th>prompt8_diff</th>\n",
       "      <th>prompt8_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The drivers conceal those busy guests.</td>\n",
       "      <td>The drivers conceal those busy guest.</td>\n",
       "      <td>blimp</td>\n",
       "      <td>determiner_noun_agreement_with_adjective_1</td>\n",
       "      <td>determiner_noun_agreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-63.698022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.507812</td>\n",
       "      <td>-0.796875</td>\n",
       "      <td>0.289062</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paul isn't talking about those scared pedestri...</td>\n",
       "      <td>Paul isn't talking about those scared pedestrian.</td>\n",
       "      <td>blimp</td>\n",
       "      <td>determiner_noun_agreement_with_adjective_1</td>\n",
       "      <td>determiner_noun_agreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-59.329580</td>\n",
       "      <td>...</td>\n",
       "      <td>1.429687</td>\n",
       "      <td>True</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>-0.742188</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.523438</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A lot of actors discover that gray shoe.</td>\n",
       "      <td>A lot of actors discover that gray shoes.</td>\n",
       "      <td>blimp</td>\n",
       "      <td>determiner_noun_agreement_with_adjective_1</td>\n",
       "      <td>determiner_noun_agreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>-57.873740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>-1.156250</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.742188</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benjamin messes up these black hospitals.</td>\n",
       "      <td>Benjamin messes up these black hospital.</td>\n",
       "      <td>blimp</td>\n",
       "      <td>determiner_noun_agreement_with_adjective_1</td>\n",
       "      <td>determiner_noun_agreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>-58.381034</td>\n",
       "      <td>...</td>\n",
       "      <td>1.117188</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.265625</td>\n",
       "      <td>-0.914063</td>\n",
       "      <td>0.648438</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.156250</td>\n",
       "      <td>-0.929688</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most organizations appreciate these good cafes.</td>\n",
       "      <td>Most organizations appreciate these good cafe.</td>\n",
       "      <td>blimp</td>\n",
       "      <td>determiner_noun_agreement_with_adjective_1</td>\n",
       "      <td>determiner_noun_agreement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>-55.305567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>True</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.218750</td>\n",
       "      <td>-0.687500</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sentence_grammatical  \\\n",
       "0             The drivers conceal those busy guests.   \n",
       "1  Paul isn't talking about those scared pedestri...   \n",
       "2           A lot of actors discover that gray shoe.   \n",
       "3          Benjamin messes up these black hospitals.   \n",
       "4    Most organizations appreciate these good cafes.   \n",
       "\n",
       "                              sentence_ungrammatical source  \\\n",
       "0              The drivers conceal those busy guest.  blimp   \n",
       "1  Paul isn't talking about those scared pedestrian.  blimp   \n",
       "2          A lot of actors discover that gray shoes.  blimp   \n",
       "3           Benjamin messes up these black hospital.  blimp   \n",
       "4     Most organizations appreciate these good cafe.  blimp   \n",
       "\n",
       "                                     paradigm                 phenomenon  \\\n",
       "0  determiner_noun_agreement_with_adjective_1  determiner_noun_agreement   \n",
       "1  determiner_noun_agreement_with_adjective_1  determiner_noun_agreement   \n",
       "2  determiner_noun_agreement_with_adjective_1  determiner_noun_agreement   \n",
       "3  determiner_noun_agreement_with_adjective_1  determiner_noun_agreement   \n",
       "4  determiner_noun_agreement_with_adjective_1  determiner_noun_agreement   \n",
       "\n",
       "   LS_grammatical  LS_ungrammatical  LS_diff  pair_ID  direct_sum_score_gram  \\\n",
       "0             NaN               NaN      NaN        0             -63.698022   \n",
       "1             NaN               NaN      NaN        1             -59.329580   \n",
       "2             NaN               NaN      NaN        2             -57.873740   \n",
       "3             NaN               NaN      NaN        3             -58.381034   \n",
       "4             NaN               NaN      NaN        4             -55.305567   \n",
       "\n",
       "   ...  prompt6_diff  prompt6_ans  prompt7_gram  prompt7_ungram  prompt7_diff  \\\n",
       "0  ...      0.679688         True     -0.406250       -0.750000      0.343750   \n",
       "1  ...      1.429687         True      0.085938       -0.742188      0.828125   \n",
       "2  ...      0.492188         True     -0.765625       -1.156250      0.390625   \n",
       "3  ...      1.117188         True     -0.265625       -0.914063      0.648438   \n",
       "4  ...      0.968750         True      0.046875       -0.875000      0.921875   \n",
       "\n",
       "  prompt7_ans prompt8_gram  prompt8_ungram  prompt8_diff  prompt8_ans  \n",
       "0        True    -0.507812       -0.796875      0.289062         True  \n",
       "1        True    -0.171875       -0.523438      0.351562         True  \n",
       "2        True    -0.742188       -0.875000      0.132812         True  \n",
       "3        True    -0.156250       -0.929688      0.773438         True  \n",
       "4        True    -0.218750       -0.687500      0.468750         True  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_aj_data = process_aj_data(models=MODELS)\n",
    "all_aj_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_long(df, columns_keep,num_prompts):\n",
    "    \"\"\"Converts the dataframe to long format.\"\"\"\n",
    "    df_long = pd.melt(df, id_vars=columns_keep,value_vars=[f'prompt{i}_diff' for i in range(1,num_prompts+1)]+[f'prompt{i}_ans' for i in range(1,num_prompts+1)], var_name='metric', value_name='value')\n",
    "    df_long['promptID'] = df_long['metric'].str.extract(r'(\\d+)').astype(int)\n",
    "    df_long_ans = df_long[df_long['metric'].str.contains('ans')]\n",
    "    df_long_diff = df_long[df_long['metric'].str.contains('diff')]\n",
    "    df_long = df_long_ans.merge(df_long_diff, on=columns_keep+['promptID'], suffixes=('_ans', '_diff'))\n",
    "    df_long.rename(columns={'value_ans': 'ans', 'value_diff': 'diff'}, inplace=True)\n",
    "    return df_long\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr1_columns = ['model', 'dataset', 'model_family', 'model_gen','model_size', 'model_type','pair_ID','sumLP_diff', 'meanLP_diff', 'sumLP_ans', 'meanLP_ans']\n",
    "aj_long = convert_to_long(all_aj_data, expr1_columns, 8)\n",
    "aj_long.to_csv('alldata/expr1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 (word prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wp_data(folder='continuation',testsuite=None,models=None):\n",
    "    df = read_model_csvs(f'model_output/{folder}')\n",
    "    if testsuite is not None:\n",
    "        df = df[df.dataset.isin(testsuite)]\n",
    "    if models is not None:\n",
    "        df = df[df.model.isin(models)]\n",
    "    \n",
    "    df['sumLP_diff'] = df['direct_score_1'] - df['direct_score_2']\n",
    "    df['sumLP_ans'] = df['direct_correct']\n",
    "    \n",
    "    # process_prompts 1 to 4\n",
    "    for i in range(1,5):\n",
    "        pid=i\n",
    "        df[f'prompt{pid}_diff'] = df[f'prompt{i}_score_gram'] - df[f'prompt{i}_score_ungram']\n",
    "        df[f'prompt{pid}_ans'] = df[f'prompt{i}_correct']\n",
    "    \n",
    "    # process prompt 5 (we didn't use prompt 5 in our study as the . is missing)\n",
    "    for i in [5]:\n",
    "        pid = i\n",
    "        df[f'prompt{pid}_gram'] = df[f'prompt{i}_score_gram'] - df[f'prompt{i}_score_ungram']\n",
    "        df[f'prompt{pid}_ungram'] = df[f'prompt{i+1}_score_gram'] - df[f'prompt{i+1}_score_ungram']\n",
    "        df[f'prompt{pid}_diff'] = df[f'prompt{pid}_gram'] - df[f'prompt{pid}_ungram']\n",
    "        df[f'prompt{pid}_ans'] = df[f'prompt{pid}_gram'] > df[f'prompt{pid}_ungram']\n",
    "    \n",
    "    for i in [7,8]:\n",
    "        pid = i-1\n",
    "        df[f'prompt{pid}_diff'] = (df[f'prompt{i}_score_1'] + df[f'prompt{i}_score_1_reverse'] - df[f'prompt{i}_score_2'] - df[f'prompt{i}_score_2_reverse'])/2\n",
    "        df[f'prompt{pid}_ans'] = df[f'prompt{pid}_diff'] > 0\n",
    "        \n",
    "    #df = model_rename(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>prefix</th>\n",
       "      <th>good_continuation</th>\n",
       "      <th>bad_continuation</th>\n",
       "      <th>log_freq</th>\n",
       "      <th>log_freq_alter</th>\n",
       "      <th>prediction_direct</th>\n",
       "      <th>prediction_prompt</th>\n",
       "      <th>direct_score_1</th>\n",
       "      <th>direct_score_2</th>\n",
       "      <th>...</th>\n",
       "      <th>prompt4_diff</th>\n",
       "      <th>prompt4_ans</th>\n",
       "      <th>prompt5_gram</th>\n",
       "      <th>prompt5_ungram</th>\n",
       "      <th>prompt5_diff</th>\n",
       "      <th>prompt5_ans</th>\n",
       "      <th>prompt6_diff</th>\n",
       "      <th>prompt6_ans</th>\n",
       "      <th>prompt7_diff</th>\n",
       "      <th>prompt7_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jabberwocky_0</td>\n",
       "      <td>between crafty fur wee anaesthesia , yore `` b...</td>\n",
       "      <td>channel</td>\n",
       "      <td>backgrounds</td>\n",
       "      <td>8.828641</td>\n",
       "      <td>8.827468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.590733</td>\n",
       "      <td>-12.222569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039062</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.359375</td>\n",
       "      <td>-1.414062</td>\n",
       "      <td>0.054687</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.935547</td>\n",
       "      <td>False</td>\n",
       "      <td>0.449219</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jabberwocky_1</td>\n",
       "      <td>a hole nominate pride in afford teenage jacket...</td>\n",
       "      <td>fallacy</td>\n",
       "      <td>astute</td>\n",
       "      <td>5.676754</td>\n",
       "      <td>5.676754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.584092</td>\n",
       "      <td>-10.420748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.328125</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>False</td>\n",
       "      <td>0.021650</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.051747</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jabberwocky_2</td>\n",
       "      <td>i liked well compass fatal after encompass pur...</td>\n",
       "      <td>absent</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>7.738924</td>\n",
       "      <td>7.738924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.230927</td>\n",
       "      <td>-10.662567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.828125</td>\n",
       "      <td>-0.976562</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>True</td>\n",
       "      <td>0.783203</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jabberwocky_3</td>\n",
       "      <td>thou sly splash contrive occupy sew all parami...</td>\n",
       "      <td>regiment</td>\n",
       "      <td>brute</td>\n",
       "      <td>7.474205</td>\n",
       "      <td>7.474205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.204615</td>\n",
       "      <td>-9.860865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>-0.742188</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>True</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>True</td>\n",
       "      <td>3.669922</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jabberwocky_4</td>\n",
       "      <td>that observe overhead attest some circuit unto...</td>\n",
       "      <td>turmoil</td>\n",
       "      <td>squeakers</td>\n",
       "      <td>6.276643</td>\n",
       "      <td>6.276643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19.665796</td>\n",
       "      <td>-22.950417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.570312</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.070312</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.054291</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.413825</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id                                             prefix  \\\n",
       "0  jabberwocky_0  between crafty fur wee anaesthesia , yore `` b...   \n",
       "1  jabberwocky_1  a hole nominate pride in afford teenage jacket...   \n",
       "2  jabberwocky_2  i liked well compass fatal after encompass pur...   \n",
       "3  jabberwocky_3  thou sly splash contrive occupy sew all parami...   \n",
       "4  jabberwocky_4  that observe overhead attest some circuit unto...   \n",
       "\n",
       "  good_continuation bad_continuation  log_freq  log_freq_alter  \\\n",
       "0           channel      backgrounds  8.828641        8.827468   \n",
       "1           fallacy           astute  5.676754        5.676754   \n",
       "2            absent       aggressive  7.738924        7.738924   \n",
       "3          regiment            brute  7.474205        7.474205   \n",
       "4           turmoil        squeakers  6.276643        6.276643   \n",
       "\n",
       "   prediction_direct  prediction_prompt  direct_score_1  direct_score_2  ...  \\\n",
       "0                NaN                NaN       -9.590733      -12.222569  ...   \n",
       "1                NaN                NaN      -10.584092      -10.420748  ...   \n",
       "2                NaN                NaN       -9.230927      -10.662567  ...   \n",
       "3                NaN                NaN      -10.204615       -9.860865  ...   \n",
       "4                NaN                NaN      -19.665796      -22.950417  ...   \n",
       "\n",
       "   prompt4_diff prompt4_ans prompt5_gram  prompt5_ungram  prompt5_diff  \\\n",
       "0     -0.039062       False    -1.359375       -1.414062      0.054687   \n",
       "1     -0.007812       False    -0.351562       -0.328125     -0.023438   \n",
       "2      0.093750        True    -0.828125       -0.976562      0.148438   \n",
       "3      0.070312        True    -0.734375       -0.742188      0.007813   \n",
       "4      0.054688        True    -0.570312       -0.500000     -0.070312   \n",
       "\n",
       "   prompt5_ans  prompt6_diff  prompt6_ans  prompt7_diff  prompt7_ans  \n",
       "0         True     -0.935547        False      0.449219         True  \n",
       "1        False      0.021650         True     -0.051747        False  \n",
       "2         True      0.783203         True      0.009766         True  \n",
       "3         True      0.750000         True      3.669922         True  \n",
       "4        False     -1.054291        False     -0.413825        False  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_wp_data = process_wp_data(models=MODELS)\n",
    "all_wp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_columns = ['model', 'dataset', 'model_family', 'model_gen','model_size', 'model_type','item_id','sumLP_diff', 'sumLP_ans']\n",
    "wp_long = convert_to_long(all_wp_data, wp_columns, 7)\n",
    "wp_long.rename(columns={'item_id': 'pair_ID'}, inplace=True)\n",
    "wp_long.to_csv('alldata/expr2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
